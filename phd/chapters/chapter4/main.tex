\chapter{Conclusions}\label{chapter: conclusions}
In this thesis we have presented how guided I/O interfaces, found at different level of the I/O stack, can be exploited to drive prefetching and move data across different storage tiers. Particularly we have shown how file system level hints can be used to modify the read profile of a ROOT based application that normally performed badly due to the nature of the adopted I/O pattern (equivalent to small random reads). We have integrated the file system level hints in a separate I/O middleware (Mercury) able to transparently guide data prefetching basing on users specifications (defined inside a configuration file). We have also shown like parallel file systems can greatly benefit from this mechanism (especially Lustre).

Additionally, we have also shown how caching can be extremely useful in parallel write operations, collective writes more precisely, to reduce the effect of global synchronisation and memory pressure. This has been done by extending the MPI-IO hints available in ROMIO to include new cache hints. These cache hints were then used to select the local NVM cache tier to write data to. Locally cached data was afterwards synchronised with the global file system in the back ground while the application was doing computation.

Our work has set the scene for further development in several areas. First of all Mercury is able to feed hints into the file system but is not able to generate them autonomously, that is, Mercury cannot learn the application I/O pattern and take appropriate actions by itself. In our environment hints were selected manually for a specific ROOT application to get best performance results. The automatic extraction of I/O pattern profile information is very important. All the analysis tools, including the ones we have used, approach the I/O pattern analysis problem from an ultra fine-grain point of view (i.e. considering the offset and length of requests) with the result of having a very specific file per application characterisation. On the other hand, in this work we have observed that a course-grain approach (i.e. considering blocks instead of single requests) can be more beneficial when trying to extract the general application behaviour. The study of automatic I/O pattern analysis tools with the described features therefore becomes an interesting research topic of its own.

Second, since in Chapter~\ref{chapter: } we have focused on collective write operations the use of locally attached NVM for data prefetching in ROMIO still needs to be evaluated. Moreover, although our approach has proven to be effective for parallel write operations we did not explore the use of more complex caching policies or automatic data migration mechanisms based, for example, on user defined policies. This topic is of great importance due to the explosion of new memory technologies. Efficient HPC systems will need to exploit these new memory technologies in order to scale properly. In this direction the Exascale10 initiative, of which this work represents a small part, plans to include these features and more into an exascale ready I/O middleware.

