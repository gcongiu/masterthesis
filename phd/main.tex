\documentclass[a4paper,titlepage,oneside,11pt]{book}
%*******************************************************************************************
% USEPACKAGE
%*******************************************************************************************
\usepackage[ansinew]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[english]{babel}
\usepackage{indentfirst}
\usepackage{makeidx}
\usepackage{graphicx}
\usepackage[usenames]{color}
\usepackage{float}
\usepackage{amsmath,amssymb}
\usepackage{multicol}
\usepackage{multirow/multirow}
\usepackage{calc}
\usepackage{caption}
\usepackage{subcaption}
\usepackage[a4paper,top=4.5cm,bottom=4.5cm,left=4.5cm,right=4.5cm]{geometry}
\usepackage[pdfauthor={Giuseppe Congiu},pdftitle={PhD Thesis},bookmarks,colorlinks]{hyperref}
\usepackage[all]{hypcap}
\usepackage{fancyvrb}
\usepackage{fancybox}
\usepackage{paralist}
\usepackage{listings}
\usepackage{acronym}
\usepackage{array, booktabs}
\usepackage{microtype}
\usepackage[htt]{hyphenat}
%\usepackage[natbib=true, style=numeric-comp, backend=bibtex8,defernumbers, maxnames=99]{biblatex}
%\usepackage{natbib}
%\usepackage{bibunits}
%\newcommand{\codeword}{\texttt}
\newcommand{\ra}[1]{\renewcommand{\arraystretch}{#1}}
\newcolumntype{M}[1]{>{\centering\arraybackslash}m{#1}}
%\usepackage{mypref}
%*******************************************************************************************
% END USEPACKAGE
%*******************************************************************************************
\pagestyle{headings}
\definecolor{myblue}{rgb}{0,0,1}
\definecolor{mygreen}{rgb}{0,0.6,0}
\definecolor{mykey}{rgb}{0.7,0.4,0}
\definecolor{stringa}{rgb}{1,0.4,0}
\newcommand{\codeword}{\texttt}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}
 
\lstdefinestyle{mystyle}{
        backgroundcolor=\color{backcolour},   
        commentstyle=\color{codegreen},
        keywordstyle=\color{magenta},
        numberstyle=\tiny\color{codegray},
        stringstyle=\color{codepurple},
        basicstyle=\small\ttfamily,
        breakatwhitespace=false,         
        breaklines=true,                 
        captionpos=b,                    
        keepspaces=true,                 
        numbers=left,                    
        numbersep=5pt,                  
        showspaces=false,                
        showstringspaces=false,
        showtabs=false,                  
        tabsize=2
}

\lstset{style=mystyle}
%*******************************************************************************************
% FRONTESPIZIO
%*******************************************************************************************
% title
\title{Exploiting File Caching Infrastructures in HPC Using Guided I/O Interfaces}
%\title{Improving I/O Performance in HPC Using Hint Driven Caching}

%authors
\author{Giuseppe Congiu}

\makeglossary
\makeindex

\begin{document}

\hypersetup{citecolor=black,filecolor=black,linkcolor=black,urlcolor=blue} %settare i calori dei link

\begin{titlepage}
\thispagestyle{empty}

\begin{flushleft}
\vbox to0pt{
\vbox to\textheight{\vfil
\vspace{10cm}
\includegraphics[width=5cm]{figures/uni-mainz}
\vfil}\vss}
\end{flushleft}

\begin{center}
        \large JOHANNES GUTENBERG UNIVERSIT{\"A}T MAINZ \\
        \large \textbf{Department of Computer Science}
\end{center}

\begin{center}
	\vspace{2cm}{
                \Huge \textsc{\textbf{Exploiting File Caching Infrastructures in HPC Using Guided I/O Interfaces and Non-Volatile Memory Devices}} \\
	        \vspace{0.45cm}
	        \rule{\textwidth}{1.5mm}
        } \\
	\vspace{0.2cm}
\end{center}
\vspace{3cm}

\begin{flushright}
	Candidate:\\
	\textbf{Giuseppe Congiu}\\
	Version 1.0, \today
\end{flushright}

\begin{flushright}
	Advisors:\\
	\textbf{Prof. Dr. Andr\'e Brinkmann}\\
        \textbf{Dr. Sai Narasimhamurthy}
\end{flushright}

\end{titlepage}
%*******************************************************************************************
%END FRONTESPIZIO
%*******************************************************************************************

\newpage
\thispagestyle{empty}
\newpage
%\begin{center}
%\textit{To my family.}\\
%\textit{Dedicato alla mia famiglia che mi \`e sempre stata vicino in questi anni.}
%\end{center}
%\pagenumbering{roman}\setcounter{page}{1}
\newpage
\thispagestyle{empty}
\null
\newpage
\pagenumbering{roman}\setcounter{page}{1}
\tableofcontents
\mainmatter

%\begin{bibunit}
% The \nocite{*} command simply lists all of the references found in the 
% bibliography file, without a corresponding reference number in the text.
%\nocite{*}
% Here publications refers to our "publications.bib" file containing our 
% publications list. Change it to the path to your publications list file
%\putbib[publications]
%\end{bibunit}

%*******************************************************************************************
% CHAPTERS
%*******************************************************************************************
\pagenumbering{roman}\setcounter{page}{3}
\chapter*{Acknowledgments}
This work would have not been possible without the many people that I have worked with in these years at Xyratex and Seagate. First of all Malcolm Muggeridge that offered me the possibility to work with his team of professionals.
Among the people in the team special thanks go to Dr. Sai Narasimhamurthy for his technical supervision and to Stuart Smithson for his helpful advice and encouragement. I would also like to thank my academic advisor Prof. Andr\'e 
Brinkmann for his valuable help in overcoming difficulties with the progression of the Ph.D. and to all his team of Ph.D. students and Postdocs I had the pleasure to work with. Finally, I cannot forget my family and friends that 
supported me morally during all these years. 

\vspace{\fill}
This work has been funded by the FP7 program of the European Commission through the Scalus and DEEP-ER (Grant Agreement no. 610476) projects and it has been supported by the Exascale1O (E10) initiative.

\chapter*{\centering \small Abstract} \addcontentsline{toc}{chapter}{Abstract} 
Large scale high performance computing clusters can be composed of thousands of compute nodes with hundreds of cores each, connected through a low-latency, high-bandwidth network fabric. These large systems typically 
rely on a smaller dedicated cluster to persistently store and retrieve data. Storage clusters of this type can have thousands of hard disk drives, distributed across hundreds of I/O nodes connected through a storage 
area network. All the available storage resources are managed by a distributed parallel file system software. The performance gap between storage and compute components causes scientific applications running on high performance 
computing clusters to spend a large amount of time waiting on I/O operations, thus wasting CPU cycles. This problem will be exacerbated as we enter the Exascale computing era, since technological advancements in storage
and compute do not progress at the same pace. In this context file caching represents a viable mechanism to mitigate this technological gap. File caching exploits spatial and temporal locality of data to retain parts 
of the file in main memory, a dynamic random access memory. In this way requests targeting cached data can be served in main memory, saving the application a network round trip to retrieve the data from the remote I/O nodes,
ultimately reducing I/O latency. Spatial locality is normally exploited for sequential file read patterns using the read-ahead mechanism. When using read-ahead, the file system reads into the cache more data than originally 
requested by the application (prefetch), assuming that this will have a high probability of being requested in the future. Temporal locality, on the other hand, reflects on the cache replacement policy and is exploited by evicting 
from the cache the least recently accessed data first, assuming that older data has a lower probability of being requested in the future. These policies are based on suboptimal heuristics. Unfortunately, scientific codes can generate 
complex I/O patterns and the use of simple heuristics by the file system might result in more harm than good for the application's performance. Fortunately, file systems often provide mechanisms allowing programmers to disclose 
I/O pattern knowledge to the lower layers of the I/O software stack through a hints API. The file system can use the hints information to guide data prefetching into the cache or to disable read-ahead if the I/O pattern is random. 
The problem with hints APIs is that these are rarely used in practice, missing the opportunity of taking advantage of the full potential of the storage system. 
In the first part of this thesis we present Mercury, a transparent guided I/O middleware that exploits the hints APIs provided by different file systems to optimize file I/O patterns in scientific codes, allowing programmers and 
administrators to control the I/O behaviour of applications without the need of modifying them. Mercury provides users with a simple mechanism to describe I/O patterns. The I/O pattern description is decoupled from the specific
hints API used underneath by the file system, making our solution portable. We demonstrate that Mercury is especially helpful in converting a large number of small non-contiguous requests into a smaller number of large sequential 
requests using a mechanism called data sieving.

\vspace{5mm}
File caching is also useful in improving performance of write operations using a write-back approach. In this case the cache temporarily stores data updates on behalf of the file system, allowing control to be returned to the 
application which can progress doing useful work. Concurrently the file system moves (or flushes) updates from the cache to the file after a certain interval of time has elapsed. The length of this interval depends on a number of factors 
such as memory utilization, frequency of updates and so on. Alternatively the user can enforce data to be flushed to the file by issuing either a `fsync()' or a `close()' operation to the file system.
Write-back caching can drastically improve write performance. However, the amount of available memory per core as we move to Exascale is expected to reduce, thus reducing the memory capacity that can be dedicated to the caching of large datasets.
Nowadays, compute nodes in high performance computing clusters frequently have access to locally attached solid state drives, which effectively provide an additional tier in the storage hierarchy. Nevertheless, local storage resources 
are not always fully integrated in the I/O stack. In the second part of this thesis we present a solution to make locally attached, block based, non-volatile memory devices directly available to applications through the MPI-IO interface, 
a widely adopted parallel I/O API. We demonstrate that local storage resources can be used as persistent file cache layer to boost performance of parallel write operations, and more specifically of collective write operations to 
a shared file.
\newpage

\pagenumbering{arabic}\setcounter{page}{5}
\input{chapters/introduction}
\part{Read Patterns Optimization Using I/O Hints}
\input{chapters/kernel}
\input{chapters/mercury}
%\input{chapters/chapter1/main}
%\input{chapters/chapter2/main}
\part{Write Patterns Optimization Using NVM Devices}
\input{chapters/mpio}
\input{chapters/deeper}
\input{chapters/conclusions}
%\input{chapters/chapter3/main}
%\input{chapters/chapter4/main}
\cleardoublepage

%*******************************************************************************************
% END OF CHAPTERS
%*******************************************************************************************

%*******************************************************************************************
% BIBLIOGRAPHY
%*******************************************************************************************
\cleardoublepage
\addcontentsline{toc}{chapter}{Bibliography}

\bibliographystyle{alpha}
\bibliography{bibliography}

%*******************************************************************************************
% LIST OF FIGURES
%*******************************************************************************************
\listoffigures
\cleardoublepage

%*******************************************************************************************
% LIST OF TABLES
%*******************************************************************************************
\listoftables
\cleardoublepage

%*******************************************************************************************
%END BIBLIOGRAFIA
%*******************************************************************************************
\end{document}
%*******************************************************************************************
%*******************************************************************************************
%  END   DOCUMENT 
%*******************************************************************************************
%*******************************************************************************************
