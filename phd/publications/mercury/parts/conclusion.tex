%!TEX root = ../main.tex
\section{Conclusion \& Future Work}
\label{sec: conclusion}

In this paper we presented a guided I/O framework prototype that can be used to set POSIX advice and GPFS hints on behalf of applications transparently to the user. This is done by adding annotations regarding which regions of a file to prefetch into a configuration file that is afterwards fed to the \textit{Assisted I/O library} and \textit{Advice Manager} modules. %We demonstrated that using our prototype the non-optimal I/O pattern of a real application can be adapted to the underlying storage system to improve performance. %This is useful for all those applications that access their data using an immutable I/O pattern, like the `ROOT' application here presented.

%We focused predominantly on read patterns which characterize a class of scientific applications known as big data science analytics. These class of applications differ from HPC applications in the type of I/O pattern they use. Indeed, HPC applications are dominated by writing of large amounts of checkpoint data to a shared (N-1 pattern) or multiple files (N-N pattern) for restart purposes or, more generally, for post processing. Big data analytics applications, on the other hand, read large amounts of input data for processing and write very little volumes of output data (results) to the file system. Currently, there is a convergence of these two paradigms that brings big data analytics applications to run on high-end computing clusters, typically as post processing phase for data generated by HPC applications such as, e.g., climate and earthquake simulations. Here we considered `ROOT' as representative for big data science analytics and we demonstrated that by using the hints API provided by the file system in an appropriate way it is possible to improve the storage system usage and ultimately the application performance.  
 
In the future we plan to further explore the problem of data science analytics applications in HPC, studying more profusely the different types of existing I/O patterns and how hints can be used to improve the cache utilization efficiency and thus applications' performance. Moreover, although not explicitly treated here, we recognise how important is to automatically extract information concerning the application's I/O pattern profile. Almost all the current analysis tools, including the ones we have used, approach the I/O pattern analysis problem from an ultra fine-grain point of view (i.e. considering the offset and length requests) with the result of having a very specific file per application characterization. On the other hand, in this work we have observed that a course-grain approach (i.e. considering blocks instead of single requests) can be more beneficial when trying to extract the general application behaviour. The study of an automatic I/O pattern analysis tool with the described features will be thus part of future work. 
%In the future we plan to extend the \textit{Advice Manager} to provide support for MPI I/O hints that currently have to be hard coded into the application. In this way administrators could use our mechanism to change, for instance, the striping policy of a specific file to adapt it to the underlying storage system configuration, without modifying the application. The integration of cluster aware I/O support will also compensate for the lack of file access global scope in the current version. 

%TODO: consider a comment about how this won't work as a cluster-aware installation - open files are not shared between nodes, they have an independent view. 

%TODO: a criticism may be that 'we never run the application with the same data', and 'changing the data changes the applications behaviour', so the learning approach isn't valid. A sentence or two to explain that while the data may change, the manner in which the program accesses it does not. A good example of this is a climate simulator.
