\chapter{Cell Broadband Engine Architecture}\label{cap:capitolo1}

\section{Storia del progetto}
Il progetto per lo sviluppo del Cell ha avuto inizio con il via libera da parte degli amministratori delegati delle compagnie Sony e IBM. Sony in qualità di fornitore di contenuti e IBM come guida nello sviluppo tecnologico. A tale collaborazione si è aggiunta poi anche Toshiba, in veste di supporter per la produzione su larga scala. Questo ha portato, durante l'estate del 2000, ad un confronto ad alto livello sull'architettura da adottare.\\ Durante un importante meeting a Tokyo, si è giunti alla conclusione che le configurazioni architetturali tradizionali non permettevano il raggiungimento delle potenze computazionali che Sony cercava per i suoi prodotti interattivi futuri. L'obiettivo del Cell doveva essere quello di centuplicare le prestazioni della PS2 e tracciare una via per futuri sviluppi.\\
A questo livello dell'interazione sono state coinvolte la divisione di ricerca della IBM, con lo scopo di esplorare nuovi approcci nella progettazione e la IBM process technology, la quale ha contribuito con l'introduzione di un processo tecnologico a 90nm silicon-on-insulator (SOI), dielettrici con bassa $\epsilon_r$ e interconnessioni in rame\cite{Yang}. \\
Il consorzio STI (Sony-Toshiba-IBM) mirava alla realizzazione un centro digitale che, oltre ad aspetti di intrattenimento, fondesse anche elementi di interconnessione a banda larga e supercomputer.
Durante queste interazioni sono state proposte una larga varietà di soluzioni di tipo multi-core che andavano dai multiprocessori convenzionali ai multiprocessori orientati al dataflow\footnote{Sistemi multiprocessore orientati all'elaborazione di flussi di dati, come ad esempio video e musica.}.\\
Alla fine del 2000 si è giunti a una nuova architettura sulla quale venivano combinati un processore Power a 64-bit\cite{PowerArchitecture} con memory flow control e dei processori detti \emph{synergistic}, che permettevano di fornire le densità computazionali richieste e un efficente gestione del consumo di potenza. 
Dopo diversi mesi di discussioni architetturali, il centro di progettazione STI è stato formalmente aperto ad Austin, in Texas, il 9 Marzo del 2001.\\
Per portare a compimento la realizzazione del processore Cell sono stati impiegati un certo numero di elementi chiave. Per prima cosa, si è adottato un approccio olistico\footnote{Paradigma scientifico che si pone lo studio dei sistemi complessi separandoli nelle loro componenti e studiandone separatamente le proprietà.} a tutti i livelli di progettazione, a partire dall'architettura del processore, passando per l'implementazione hardware, la struttura del sistema e il modello di programmazione del software. Secondo, IBM ha distribuito, tra varie località, il progetto del sistema. Terzo, il progetto ha incorporato molti elementi flessibili come synergistic processor riprogrammabili e interfacce di I/O riconfigurabili, in modo da supportare, con un solo chip ad alto volume, diverse configurazioni di sistema.


\section{Obiettivi e sfide}

Tra gli obiettivi che i progettisti si sono preposti per la nuova architettura, di seguito ne illustriamo i principali.

\subsubsection{Miglioramento delle performance} 
Quello del raggiungimento di prestazioni elevate, specialmente in campo multimediale e video ludico, è stato il primo dei punti preso in esame per lo sviluppo del progetto. Tale obiettivo ha visto la sfida alla limitazione delle performance, imposta dalla latenza delle memorie, attraverso l'aumento della frequenza di clock, ottenuta riducendo il carico di lavoro per ciclo e aumentando la profondità della pipeline.\\
Attualmente, la principale limitazione all'aumento delle prestazioni nelle CPU è rappresentata proprio dal così detto fenomeno del \emph{memory wall}\cite{memorywall}. Con memory wall, si fa riferimento all'aumento continuo, ad ogni generazione, del divario operativo che si ha tra le memorie e i processori. Tale divario è imputato al fatto che l'incremento continuo delle frequenze di clock, nelle CPU, non incontra una corrispondente riduzione della latenza nelle memorie DRAM. Normalmente, nei processori che hanno frequenze di clock dell'ordine dei GHz è comune, per la memoria, avere latenze che si aggirano intorno al centinaio di cicli di clock; tale valore aumenta quando si prendono in considerazione architetture multiprocessore simmetriche\footnote{Con multiprocessore simmetrico si intende un'architettura omogenea costituita da diverse CPU che hanno accesso a una memoria condivisa.}, arrivando al migliaio di cicli. 
Un microprocessore convenzionale, che utilizza un approccio alla programmazione di tipo sequenziale, è capace di sostenere un numero limitato di transazioni concorrenti con la memoria. Infatti, in un modello sequenziale, si assume che ogni istruzione venga completata prima che l'esecuzione della successiva abbia inizio; se una di queste causa un cache miss, si ha un accesso alla memoria principale. A questo punto, l'esecuzione delle istruzioni può continuare in modo speculativo, assumendo che l'accesso abbia avuto successo. Il processore deve registrare lo stato precedente all'esecuzione dell'istruzione, in modo da poterlo ripristinare nel caso in cui questa non vada a buon fine. A causa del carico computazionale, richiesto dall'esecuzione speculativa delle istruzioni e poiché la probabilità della buona riuscita nell'esecuzione di queste ultime diminuisce rapidamente all'aumentare del loro numero, è estremamente raro, per microprocessori convenzionali, avere più di pochi accessi concorrenti alla memoria. In tali sistemi, le limitazioni sulla banda della memoria sono indotte dalla latenza e cercare di aumentare la banda a spese della latenza può risultare controproducente.\\ 
Un altro aspetto non trascurabile è quello del consumo di potenza, che nei processori basati su tecnologia CMOS è aumentato stabilmente, tanto che oggi ci troviamo, ancora una volta, a dover far ricorso a soffisticate tecniche di raffreddamento che erano state accantonate al termine dell'era bipolare\cite{Ghoshal}. Attualmente la situazione è critica per due ragioni. Per prima cosa, le dimensioni dei transistor sono diventate talmente ridotte da causare passaggio di cariche, per effetto tunnel, attraverso l'ossido di gate; inoltre la ristretta lunghezza dei canali porta effetti del secondo ordine (effetti di canale corto) come, ad esempio, correnti parassite che scorrono anche quando il transistor è sottosoglia. Tutti questi fenomeni fanno si che il consumo di potenza aumenti, piuttosto che diminuire, all'aumentare dello scaling geometrico dei dispositivi\cite{Isaac}.\\
In secondo luogo, non è attualmente disponibile una tecnologia alternativa che permetta la riduzione del consumo di potenza. La sfida, perciò, è trovare il modo di migliorare l'efficenza insieme alle performance\cite{Hofstee}. Un terzo ostacolo nel miglioramento delle prestazioni, viene dall'osservazione secondo la quale abbiamo raggiunto un punto di riduzione dei benefici ottenibili dall'incremento delle frequenze di clock e della profondità delle pipeline\cite{Srinivasan}. Il problema è che con l'aumento degli stadi di pipeline anche la latenza delle istruzioni aumenta a causa del maggior numero di latch. Questo porta diversi svantaggi tra cui, perdita della possibilità di caricare un'istruzione poiché quasta dipende dal risultato di una precedente e penalità associata all'errore nella predizione di un'istruzione di salto condizionato. Quando non si può far leva sull'aumento della frequenza a causa di limitazioni sulla potenza, pipeline con più stadi e quindi latenze di esecuzione maggiori, possono degradare le prestazioni piuttosto che migliorarle.

\subsubsection{Supporto al real-time}
Fin dall'inizio si è pensato che il processore Cell dovesse essere progettato per fornire la migliore esperienza possibile all'utente umano e la migliore possibile alla rete. Questo tipo di concezione differisce da quella passata nella quale l'obiettivo primario era quello di elaborare un gran numero di dati (cosi detta elaborazione batch); allora, la preoccupazione principale era appunto quella di tenere occupata la CPU. Come tutti gli sviluppatori di prodotti video ludici sanno, soddisfare il giocatore significa fornire continui aggiornamenti (real-time) dell'ambiente virtuale, in modo da rendere più realistica e coinvolgente l'esperienza di gioco. Per questo motivo il Cell è stato ideato per supportare in modo estensivo il real-time.  Allo stesso tempo, è stato anticipato che molti dei dispositivi nei quali il Cell vuole trovare impiego devono essere connessi, attraverso una connessione a banda larga, a Internet. Questo ha richiesto il supporto concorrente per sistemi operativi real-time e non real-time, usati per eseguire applicazioni che richiedono accesso a Internet. Poiché quest'ultima presenta una grande varietà di standard, come ad esempio i vari standard per lo streaming video, ogni funzione di accelerazione è stata resa programmabile e flessibile.

\subsubsection{Compatibilità con un'ampia varietà di piattaforme}
Il progetto Cell è stato guidato dal bisogno di sviluppare un processore per la futura generazione di sistemi di intrattenimento. Comunque, questa nuova architettura, oltre ad essere efficace nell'area dei giochi e dei media, grazie alla capacità di interfacciarsi ottimamente con gli utenti e con le reti a banda larga può, se progettata in modo adeguato, avere un ampio range di applicazioni nell'home digital e oltre. La Broadband Processor Architecture \cite{BPA} è stata concepita per avere una vita che vada oltre l'incarnazione nella prima generazione di processori Cell. Per fare in modo che questa nuova concezione di sistema raggiunga un'elevata popolarità e per nutrire una comunità di sviluppatori software nella quale le applicazioni siano ottimizzate per questa architettura, è stato reso disponibile un ambiente software di sviluppo Linux-based. 

\section{Concezione del progetto e architettura}
La prima generazione della CBEA (Figura~\ref{fig:cell-image}) combina un processore power a 64-bit dual-threaded, dual-issue, con otto synergistic processor elements (SPE) di nuova concezione\cite{Flachs}, un memory controller on-chip e un controller per interfacce di I/O riconfigurabili. Queste unità sono interconnesse mediante un element interconnect bus (EIB) coerente.\\
Gli elementi chiave, legati alla concezione di questa nuova architettura, sono fondamentalmente i seguenti: \textbf{1)} un sistema ideato per funzionare ad elevate frequenze di clock (numero ridotto di porte per ciclo). Questo consente al processore di operare a bassi livelli di tensione e di consumo di potenza, senza però intaccare le elevate prestazioni; \textbf{2)} compatibilità con l'architettura power, in modo da fornire un punto di accesso ai programmatori, sia per quanto riguarda il supporto ai diversi sistemi operativi che per la possibilità di mettere a frutto l'esperienza di IBM nella progettazione dei multiprocessori simmetrici; \textbf{3)} architettura Single Instruction Multiple Data (SIMD), supportata sia dalla PPE attraverso l'unità Vector Media eXtension (VMX), sia dall'Instruction Set Architecture (ISA) delle SPE, per il miglioramento delle prestazioni nel campo video ludico, scientifico e nel consumo di potenza; \textbf{4)} una PPE efficente dal punto di vista del consumo di area sul chip e del consumo di potenza, che supporta alte frequenze di funzionamento; \textbf{5)} SPE per il trasferimento coerente del carico di lavoro. Le SPE hanno delle Local Store (LS), un DMA asincrono coerente e un file register molto ampio, in modo da consentire un'elevata banda per la memoria; \textbf{6)} un element interconnect bus coerente a banda larga per consentire alle applicazioni di sfruttare in modo intensivo l'ampia banda della memoria e permettere interazioni on-chip efficenti tra le varie unità. Il bus è coerente in modo tale da avere un singolo spazio di indirizzamento, il quale viene condiviso da PPE e SPE, che rende semplice ed efficente la programmazione; \textbf{7)} interfacce di I/O a banda larga flessibili, configurabili per supportare diverse organizzazioni del sistema, includendo configurazioni a singolo chip con due interfacce di I/O e una configurazione a due processori che non richiede interfacce aggiuntive per la comunicazione; \textbf{8)} implementazione full-custom per massimizzare le performance per watt e per millimetro quadro di silicio e facilitare lo sviluppo di prodotti derivati; \textbf{9)} supporto estensivo alla gestione della potenza, debugging harware e software e analisi delle performance; \textbf{10)} tecnologia di packaging a basso costo; e \textbf{11)} processo tecnologico 90nm SOI a basso consumo di potenza.
\begin{figure}[!htbp]
	\centering
	\subfigure[\label{fig:cell-block-diagram}]{\includegraphics[width = 7cm]{figure/CBEA1}}\qquad
	\subfigure[\label{fig:cell-die}]{\includegraphics[width = 7cm]{figure/CBEA2}}
	\caption{\scriptsize{~\ref{fig:cell-block-diagram} Diagramma a blocchi del processore Cell e~\ref{fig:cell-die} foto del chip. La prima generazione di processori Cell continene un power processor element (PPE), che integra al suo interno un power core e due livelli di cache (L1 e L2), otto synergistic processor elements (SPE), ciascuno contenente un'unità direct memory access (DMA), una local store (LS) e un'unità di esecuzione (SXU), un controller per la memoria e uno per l'interfacciamento con il bus. Tutti questi dispositivi sono iterconnessi tramiute bus on-chip coerente.}}
	\label{fig:cell-image}
\end{figure}

\subsection{Progetto ad alta frequenza e bassa tensione di alimentazione}
Frequenza di clock e livello della tensione di alimentazione, sono parametri dai quali il progetto non può prescindere; questi incidono direttamente sulle prestazioni e sul consumo di potenza del sistema. In particolare, quando la tensione di alimentazione viene ridotta, l'efficenza nel consumo di potenza aumenta. Per questo motivo una soluzione adottabile è quella di utilizzare più transistor (chip più larghi) e contemporaneamente ridurre tale livello di tensione. Nella pratica esiste un limite inferiore al di sotto del quale il chip cessa di funzionare correttamente. Tale limite è spesso fissato dalle RAM statiche on-chip. \\
Fissando la minima tensione operativa, la dimensione del chip, lo \emph{switching factor}\footnote{Fattore che misura la percentuale di transistor che, in fase di commutazione, dissiperanno potenza in un dato ciclo.} e altri parametri tecnologici, come ad esempio capacità e correnti di leakage, è possibile determinare la potenza dissipata dal chip come funzione della frequenza di funzionamento. In modo duale, dato un certo budget di potenza disponibile, la tecnologia utilizzata, la minima tensione operativa e lo switching factor, sarà possibile stimare la massima frequenza operativa per una data dimensione del chip.\\
L'obiettivo del progettista diventa quindi quello di riuscire a trovare il miglior compromesso tra efficenza nel consumo di potenza e frequenza di funzionamento (minima tensione di alimentazione e massima frequenza possibile).\\
Nel caso del processore Cell, avendo eliminato molte delle cause di inefficenza legate all'elevata frequenza di funzionamento, l'obiettivo iniziale del progetto è stato avere un periodo di clock non più grande di quello di dieci inverter fun-out-of-four (FO4\footnote{Con il termine fun-out-of-four si fa riferimento al ritardo nella propagazione del segnale in una catena di inverter in cui quello che precede ha una capacità di gate quattro volte superiore a quello che segue.}). Questo valore è stato successivamente aggiustato a undici FO4, poiché il precedente portava degli svantaggi legati al consumo di area e potenza.

\subsection{Compatibilità con l'architettura power}
La Broadband Power Architecture mantiene una completa compatibilità con l'architettura power a 64-bit\cite{PowerArchitecture}. Nell'implementazione del processore Cell sono state incluse tutte le recenti innovazioni legate alla Power technology, come il supporto alla virtualizzazione e alle pagine di grandi dimensioni. In aggiunta, la compatibilità con l'architettura power fornisce una base per il porting del software esistente, incluso il sistema operativo. Benché sia richiesto del lavoro supplementare per sfruttarne appieno le performance, le applicazioni esistenti possono essere eseguite senza nessuna modifica. 

\subsection{Architettura Single Instruction Multiple Data}
Il processore Cell utilizza un'organizzazione Single Instruction Multiple Data (SIMD) sia nella Vector Unit integrata nella PPE, sia nell'ISA della SPE. L'unità SIMD è efficace nell'accelerazione delle applicazioni multimediali e poiché tutti i processori adesso ne includono una, viene integrata tramite compilatori in grado di generare istruzioni SIMD anche per codice che non ne faccia esplicitamente uso. Optando per l'estensione SIMD, sia per la PPE che per le SPE, il compito dello sviluppo e della migrazione di software verso il Cell è stato largamente semplificato. Tipicamente, un'applicazione può nascere per essere single-threaded e non usare l'estensione SIMD. Il primo passo per migliorarne le performance, può essere quello di usare SIMD nella PPE e in seguito fare uso delle SPE. Benché l'architettura SIMD sulle SPE differisca da quella nella PPE, vi è uniformità sufficente a far si che i programmatori possano progettare software che raggiunge performance considerevoli sia sull'una che sull'altra, ovviamente dopo la ricompilazione. Poiché la PPE single-threaded fornisce un ambiente di debugging e testing che è molto familiare, molti programmatori preferiscono questo tipo di approccio alla programmazione su Cell. 

\subsection{Power processor element}
La PPE (Figura~\ref{fig:PPE}) è costituita da un power core a 64-bit, ottimizzato per il funzionamento in alta frequenza e per il consumo di potenza. Il progetto in frequenza si adatta a quello di 11 FO4 delle SPE, mentre la pipeline ha una profondità di soli 23 stadi; significativamente inferiore rispetto a quella che ci si potrebbe attendere da un progetto che quasi dimezza il tempo di esecuzione in ogni stadio, se comparato a progetti più recenti\cite{Anderson,Clabes}. La microarchitettura e il diagramma di questo processore limitano la lunghezza dei percorsi e il ritardo nella comunicazione ad ogni ciclo. La PPE carica due istruzioni per volta senza eseguire alcun riordinamento dinamico (nessuna esecuzione fuori ordine). Il power core è capace di eseguire, contemporaneamente, istruzioni di due thread separati in modo da ottimizzare l'uso degli slot di caricamento, mantenere la massima efficenza e ridurre la profondità della pipeline. Le operazioni aritmetiche semplici vengono eseguite e il loro risultato propagato, in due soli cicli di clock. A causa del ritardo nell'esecuzione, nella pipeline fixed-point, anche le istruzioni di load possono essere completate e il loro risultato inoltrato, in due soli cicli. Le istruzioni floating-point in doppia precisione richiedono invece dieci cicli per l'esecuzione. \\
La PPE supporta una gerarchia di cache convenzionale con un primo livello, per dati e istruzioni, di 32-KB ciascuno e un secondo livello di 512-KB. Quest'ultima e l'address-translator cache, usano delle tabelle per la gestione delle operazioni di sostituzione dei dati che permettono al software di indirizzare le entries, aventi uno specifico range di indirizzi, verso un particolare subset della cache. Questo meccanismo permette di bloccare i dati nella cache (quando la dimensione del range di indirizzi eguaglia quella del set) e può anche essere usato per prevenire sovrascritture, dirigendo quelli per i quali è previsto l'utilizzo una sola volta, verso un particolare set. L'uso di queste funzioni permette di aumentare l'efficenza e il controllo real-time del processore.\\ 
Come detto, la PPE permette l'esecuzione simultanea, all'interno del processore, di due thread e può perciò essere vista come un multiprocessore a due vie con dataflow condiviso. Questo da al software l'illusione di due processing unit indipendenti. Tutti i registri per la gestione dello stato interno del processore sono raddoppiati, compresi quelli special-purpose, eccetto quelli che devono occuparsi delle risorse a livello di sistema, come le partizioni logiche, memoria e il thread control. Le altre risorse di memorizzazione, come le cache e le code, vengono generalmente condivise dai due thread, eccetto nel caso in cui la risorsa sia piccola o offra un forte miglioramento delle performance nelle applicazioni multithreaded.
Il processore è composto da tre unità (Figura~\ref{fig:PPE-block-diagram}). L'instruction unit (IU), responsabile del caricamento delle istruzioni, della decodifica, del branch, della distribuzione e del loro completamento. Una fixed-point execution unit (XU), responsabile delle istruzioni fixed-point e di tutte le istruzioni di load e store. Una vector scalar unit (VSU), che si occupa di tutte le istruzioni che coinvolgono vettori e operazioni floating-point.
\begin{figure}[!htbp]
	\centering
	\subfigure[\label{fig:PPE-block-diagram}]{\includegraphics[width = 13.5cm]{figure/PPE}}
	\subfigure[\label{fig:PPE-pipeline}]{\includegraphics[width = 13.5cm]{figure/PPE-pipeline}}
	\caption{\scriptsize{Power processor element (\ref{fig:PPE-block-diagram}) unità principali e (\ref{fig:PPE-pipeline}) diagramma pipeline. Carica e decodifica fino a quattro istruzioni in parallelo dalla instruction cache L1  per l'esecuzione simultanea di due thread in cicli alternati. Il core processor contiene una istanza per ogni unità di esecuzione (branch, fixed-point, load/store, floating-point (FPU) e vector media (VMX)). Le latenze del processore sono indicate in Figura~\ref{fig:PPE-pipeline} (colorate in modo da corrispondere ai blocchi della Figura~\ref{fig:PPE-block-diagram}). Le istruzioni fixed-point semplici vengono eseguite in due cicli. La penalità associata a uno sbaglio nel calcolo del salto condizionato è pari a 23 cicli ed è comparabile a quella di progetti che hanno una frequenza operativa molto inferiore.}}
	\label{fig:PPE}
\end{figure}
La IU carica quattro istruzioni per ciclo, per ogni thread, in un buffer dal quale vengono poi mandate ai successivi stadi di elaborazione (dispatching). Dopo la decodifica e il controllo delle dipendenze, le istruzioni vengono caricate a coppie di due in una execution unit. La IU può caricare fino a due istruzioni per ciclo. Sono possibili tutte le coppie di istruzioni, eccetto che per la stessa unità e nei seguenti casi: vettori semplici, vettori complessi, vettori floating-point e floating-point scalari; questi non possono essere caricati con un'altra istruzione simile (ad esempio, un vettore semplice con un vettore complesso non sono consentiti). Comunque, tali istruzioni possono essere caricate insieme ad altre come load/store, branch, fixed-point o istruzioni di permuta di vettori. Nella VSU è presente una coda che permette di disaccoppiare la pipeline floating-point da quella vettoriale. Questo rende possibile caricamento fuori ordine di istruzioni floating-point e vettoriali.\\ 
La XU è composta da un register file general-purpose di 32 elementi a 64-bit per ogni thread, un'unità di esecuzione fixed-point e un'unità di load/store. L'unità di load/store è costituita da una cache dati di primo livello, una translation cache, una coda per i miss di 8 elementi e una coda per le store di 16 elementi.\\
L'unità di esecuzione floating-point VSU è costituita da 32 registri da 64-bit per thread e in aggiunta da una pipeline 10 stadi a doppia precisione. La vector execution unit è organizzata intorno a un dataflow a 128-bit. Inoltre, contiene quattro sotto unità: semplice, complessa, di permuta e single-precision floating-point. E' presente un register file vettoriale di 32 elementi a 128-bit per ciascun thread e tutte le istruzioni sono 128-bit SIMD con dimensione variabile (2 $\times$ 64-bit, 4 $\times$ 32-bit, 8 $\times$ 16-bit e 128 $\times$ 1-bit).

\subsection{Synergistic processing element}
La SPE\cite{Asano} implementa un nuovo ISA ottimizzato per il consumo di potenza e le performance in applicazioni multimediali e computing-intensive. La SPE (Figura~\ref{fig:SPE}) opera su una memoria detta local store (LS) di 256-KB che immagazzina dati e istruzioni. Dati e istruzioni sono traferiti tra le varie local store e la memoria di sistema attraverso comandi DMA, eseguiti dalla memory flow control unit integrata all'interno della SPE. Ogni SPE supporta fino a sedici comandi DMA in sospeso. Poiché questi usano la stessa traslazione e protezione che è utilizzata dalle tabelle di pagina e segmento della PPE, gli indirizzi possono essere passati tra questa e le SPE; così il sistema operativo può condividere la memoria e gestire tutte le risorse di elaborazione in modo coerente.
\begin{figure}[!htbp]
	\centering
	\subfigure[\label{fig:SPE-block-diagram}]{\includegraphics[scale = 0.8]{figure/SPE}}
	\subfigure[\label{fig:SPE-pipeline}]{\includegraphics[scale = 0.8]{figure/SPE-pipeline}}
	\caption{\scriptsize{Organizzazione di un synergistic processor element (\ref{fig:SPE-block-diagram}) e (\ref{fig:SPE-pipeline}) pipeline. Al centro del synergistic processor vi è la local store SRAM da 256-KB. La local store supporta accessi sia a 128-byte tramite comandi di read e write da parte del DMA, come l'instruction fetch, sia a 16-byte tramite operazioni di load e store.}}
	\label{fig:SPE}
\end{figure}
L'unità DMA può essere programmata in uno dei seguenti tre modi: \textbf{1)} con istruzioni della SPE che inseriscono i commandi DMA in una coda; \textbf{2)} preparando una lista di commandi nella local store e caricandoli insieme; oppure \textbf{3)} inserendo i commandi in coda da un altro processore del sistema (con gli appropriati privilegi) usando store o commandi DMA di tipo write. Per rendere più semplice la programmazine e per permettere transazioni DMA tra varie local store, queste ultime sono mappate nella memoria principale, nonostante ciò non sono coerenti nel sistema. L'organizzazione con local store, introduce un nuovo livello di gerarchia di memoria aldilà dei registri che forniscono l'immagazzinamento dei dati nella maggior parte delle architetture di microprocessore. Questo fornisce un meccanismo per combattere il memory wall, poiché permette che un gran numero di transazioni possa avvenire contemporaneamente senza richiedere profonde esecuzioni speculative che conducono ad alti gradi di inefficenza in altri sistemi. Con una latenza della memoria principale che si avvicina al migliaio di cicli di clock, i pochi cicli richiesti per settare un commando DMA diventano un sovracarico accettabile per accedere alla memoria principale. Ovviamente, questa organizzazione del processore può fornire buoni supporti per lo streaming, grazie alla grande capienza della local store; inoltre può essere supportata una grande varietà di modelli di programmazione. 
La local store è il componente più grande di tutta la SPE ed è stato necessario implementarla in modo efficente\cite{Nakazato}. Per minimizzare l'area è stata usata una cella SRAM single-port. In modo da fornire buone prestazioni. La local store è stata progettata con porte di lettura e scrittura di due diverse dimensioni: 128-bit e 128-byte. La porta a 128-byte è utilizzata per i commandi DMA di write e read, così come per il (pre)fetch delle istruzioni. Tipicamente un commando DMA read o write di 128-byte richiede 16 colpi di clock per mettere i dati sul bus. Comunque, anche quando viene utilizzata piena banda (16-byte/ciclo), 7 cicli ogni otto rimangono disponibili per load, store e caricamento di istruzioni. In modo simile, le istruzioni sono caricate 128-byte alla volta e la pressione sulla local store è minimizzata. La priorità più alta è data ai commandi DMA, poi alle load e store, mentre l'instruction (pre)fetch avviene ogni qualvolta c'è un ciclo disponibile. E' disponibile una speciale istruzione (che non compie nessuna operazione) che, quando necessario, forza la disponibilità di uno slot temporale per un instruction fetch.
Le unità di esecuzione nelle SPE sono organizzate intorno a un dataflow a 128-bit. Un unico register file di grosse dimensioni con 128 ingressi permette a un compilatore di riordinare grandi gruppi di istruzioni in modo da nascondere le latenze nell'esecuzione. Le istruzioni sono a 128-bit SIMD e possono avere diverse configurazioni (2 $\times$ 64-bit, 4 $\times$ 32-bit, 8 $\times$ 16-bit e 128 $\times$ 1-bit). Sono caricabili fino a due istruzioni per ciclo; uno dei due slot di caricamento supporta operazioni fixed e floating-point mentre l'altro fornisce operazioni di load/store, permuta di byte e branch. Le operazioni fixed-point semplici richiedono due cicli di esecuzione mentre quelle floating-point in precisione singola e le istruzioni di load ne richiedono sei. E' supportata anche una SIMD floating-point a due vie e doppia precisione, ma la massima velocità di caricamento è una istruzione SIMD ogni sette cicli. Tutte le altre istruzioni sono completamente pipelined.
Per limitare l'hardware supplementare dedicato alla gestione dei branch, questi possono essere previsti dal programmatore o dal compilatore, tramite particolari istruzioni. In pratica si notifica all'hardware l'arrivo di un branch e il target di quest'ultimo; l'hardware risponde (assumendo che gli slot della local store siano disponibili) facendo il pre-fetching di almeno diciasette istruzioni all'indirizzo target del branch.
L'area di controllo rappresenta solamente il 10-15\% dei $10mm^2$ occupati dal core di una SPE e tuttora diverse applicazioni si avvicinano a raggiungere il picco di performance su questo processore. L'intera SPE occupa solamente $14.5mm^2$ e dissipa solo pochi watt anche quando opera a frequenze di diversi GHz. 

\subsection{Sistema di interconnessione on-chip e memoria}
Con i miglioramenti architetturali che rimuovono le limitazioni indotte dalla latenza sulla banda, la sfida successiva diventa quella di migliorare significativamente l'accesso alla memoria principale e la banda tra le unità di elaborazione e le interfacce all'interno del processore. Per questo, nella prima generazione di processori Cell è stata adottata una memoria Rambus XDR DRAM di nuova generazione\cite{XDR}. Tale memoria distribuisce 12.8 GB/s su ogni canale da 32-bit; sul processore Cell vengono impiegati due di questi canali, per una banda totale di 25.6 GB/s. Poiché all'interno del chip la banda disponibile è circa un ordine di grandezza superiore, la contesa nei trasferimenti DMA tra le unità è quasi impercettibile.

\subsection{Interfacce di I/O}
Il Cell è stato equipaggiato con interfacce di I/O configurabili a banda larga; questo in modo da poter interconnettere in modo efficente più unità e realizzare complessi sistemi multiprocessore. In Figura~\ref{fig:system-configuration} sono illustrate le varie configurazioni supportate. 
\begin{figure}[!htbp]
	\centering
	\subfigure[\label{fig:system-configuration1}]{\includegraphics[width = 7cm]{figure/system-configuration1}}\qquad
	\subfigure[\label{fig:system-configuration2}]{\includegraphics[width = 7cm]{figure/system-configuration2}}\qquad
	\subfigure[\label{fig:system-configuration3}]{\includegraphics[width = 7cm]{figure/system-configuration3}}
	\caption{\scriptsize{Diverse configurazioni di sistema per il Cell: (\ref{fig:system-configuration1}) Configurazione base per un piccolo sistema. (\ref{fig:system-configuration2}) Multiprocessore simmetrico a due core (non necessità di sistema di interfacciamento supplementare). (\ref{fig:system-configuration3}) Multiprocessore simmetrico a quattro core (IOIF: input-output interface; BIF: broadband interface).}}
	\label{fig:system-configuration}
\end{figure}

\subsection{Implementazione full-custom}
La prima generazione di processore Cell è stata fortemente ottimizzata, dal punto di vista del funzionamento ad alta frequenza e della bassa dissipazione di potenza, tramite una metodologia di progettazione full-custom. In questo contesto è stata prestata particolare attenzione alla realizzazione delle interconnessioni. Ad esempio, i bus più grandi all'interno del chip, sono stati realizzati ponendo grande cura sul livello e il posizionamento, usando tecniche di riduzione del rumore come il wire twisting. Una gran parte dei fili restanti è stata controllata manualmente per correre su uno specifico layer. Per quando riguarda la dissipazione di potenza, è stata condotta una progettazione accurata delle specifiche termiche ed elettriche del chip in modo da distribuirne in modo efficente il consumo. Inoltre, tutto il progetto fisico, comprese le interfacce, è stato reso modulare, in modo tale che i prodotti derivati variando il numero di PPE e SPE possano essere realizzati con una riduzione significativa degli sforzi. Infine, all'interno del chip sono stati supportati domini di clock multipli.  

\subsection{Funzionalità on-chip aggiuntive}
Il processore Cell include una quantità significativa di circuiteria supplementare per il supporto del power-on reset (PoR\footnote{E' un dispositivo elettronico incorporato nei circuiti integrati che rileva la potenza applicata al chip e genera un impulso di reset che si propaga all'intero circuito portando quest ultimo in uno stato conosciuto.}), del testing, dell'hardware debug e della gestione e monitoraggio di potenza e temperatura. Il progetto permette un controllo, ciclo per ciclo, degli stati dei vari latch (holding, scanning o functional) alla piena velocità del processore. Generalmente, ogni elemento contiene un'unità satellite che si interfaccia con le varie catene di scansione dentro l'unità stessa e consente la comunicazione con le funzioni di test incorporate. 

\subsection{Packaging}
Per il processore Cell è stata sviluppata una nuova tecnologia di packaging a basso costo e alte prestazioni. Il package flip-chip plastic ball grid array (FC PBGA), Figura~\ref{fig:package}, è un nuovo progetto per la distribuzione efficente della potenza sul chip. La distribuzione dei segnali ad alta velocità all'interno del package rende possibile una banda di I/O totale che supera gli 85 GB/s.
\begin{figure}[!htbp]
	\centering
	\subfigure[\label{fig:package1}]{\includegraphics[width = 7cm]{figure/package1}}\qquad
	\subfigure[\label{fig:package2}]{\includegraphics[width = 7cm]{figure/package2}}\qquad
	\caption{\scriptsize{(\ref{fig:package1}) Sezione trasversa del modulo e (\ref{fig:system-configuration2}) foto del lato superiore senza coperchio.}}
	\label{fig:package}
\end{figure}

\subsection{Processo CMOS SOI}
Il processo tecnologico adottato per la realizzazione del chip è il CMOS SOI 90nm\cite{Yang} che permette di raggiungere elevate performance mantendo bassi i consumi di potenza. Questo distribuisce i transistor SOI ad alte performance attraverso un denso livello di interconnessioni, otto livelli aggiuntivi di interconnessioni in rame e dielettrici a bassa $\epsilon_r$. 