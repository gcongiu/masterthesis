\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\AC@reset@newl@bel
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\citation{Isaac2013}
\citation{Chatrchyan2011}
\citation{Markidis2010}
\citation{Deca2013}
\citation{Sobhaninejad2011}
\citation{CarnsHABLLR11}
\citation{ChenR10}
\citation{Braam02}
\citation{SchmuckH02}
\citation{CarnsLRT}
\citation{Mcpeek2002}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chapt: introduction}{{1}{1}{Introduction}{chapter.1}{}}
\citation{Schroeder2006}
\citation{Schroeder2007}
\citation{Nieuwejaar1996}
\citation{Simitci1998}
\citation{ThakurC96}
\citation{Bent2009}
\citation{Moody2010_2}
\citation{Frings2009}
\citation{Lofstead2008}
\citation{Liu2012}
\citation{Wang2013}
\citation{Zhang2015}
\citation{Congiu2017}
\citation{Congiu2016}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Contributions}{3}{section.1.1}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Remainder}{4}{section.1.2}}
\citation{Isaac2013}
\citation{Vital2013}
\citation{Andrews2015}
\citation{Chatrchyan2011}
\citation{Markidis2010}
\citation{Deca2013}
\citation{Sobhaninejad2011}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Background}{5}{chapter.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chapt: background}{{2}{5}{Background}{chapter.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Introduction to HPC I/O}{5}{section.2.1}}
\newlabel{section: hpc-io-sys}{{2.1}{5}{Introduction to HPC I/O}{section.2.1}{}}
\citation{Fryxell2000}
\citation{Markidis2010}
\citation{Patterson1988}
\citation{POSIX}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces High-level architecture of a HPC storage system. Compute nodes are connected to servers through a low-latency network. Each RAID volume protects data against single, or multiple, disk failures. RAID volumes are contained into disk enclosures, each of which is connected to two servers using a storage area network; in this way if one of the servers fails data is still reacheable through the failover node.\relax }}{7}{figure.caption.4}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{figure: hpc-io-arch}{{2.1}{7}{High-level architecture of a HPC storage system. Compute nodes are connected to servers through a low-latency network. Each RAID volume protects data against single, or multiple, disk failures. RAID volumes are contained into disk enclosures, each of which is connected to two servers using a storage area network; in this way if one of the servers fails data is still reacheable through the failover node.\relax }{figure.caption.4}{}}
\newlabel{formula: io-time}{{2.1}{7}{Introduction to HPC I/O}{equation.2.1.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Contribution to I/O time in a distributed storage system.\relax }}{8}{figure.caption.5}}
\newlabel{figure: rpc-request}{{2.2}{8}{Contribution to I/O time in a distributed storage system.\relax }{figure.caption.5}{}}
\newlabel{formula: io-bw}{{2.2}{8}{Introduction to HPC I/O}{equation.2.1.2}{}}
\citation{Braam02}
\citation{SchmuckH02}
\citation{Welch2008}
\citation{CarnsLRT}
\citation{Mcpeek2002}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Parallel File Systems}{9}{subsection.2.1.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Simple namespace example and corresponding representation using inodes and data blocks in the file system.\relax }}{10}{figure.caption.6}}
\newlabel{figure: inode}{{2.3}{10}{Simple namespace example and corresponding representation using inodes and data blocks in the file system.\relax }{figure.caption.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces High-level architecture of a parallel file system.\relax }}{11}{figure.caption.7}}
\newlabel{figure: pfs}{{2.4}{11}{High-level architecture of a parallel file system.\relax }{figure.caption.7}{}}
\citation{Stamos1990}
\citation{Gray2006}
\citation{Zhang2001}
\citation{Fan2004}
\citation{Michalak2005}
\citation{Sinnamohideen2010}
\citation{Congiu2012}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Example of namespace distributed across four metadata servers.\relax }}{12}{figure.caption.8}}
\newlabel{figure: namespace}{{2.5}{12}{Example of namespace distributed across four metadata servers.\relax }{figure.caption.8}{}}
\@writefile{toc}{\contentsline {subsubsection}{Consistency Semantics}{12}{figure.caption.8}}
\citation{Gray1981}
\citation{Wright2007}
\citation{Wright2007}
\citation{Braam02}
\citation{SchmuckH02}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces In this case false sharing of block two in the file can lead to two different outcomes. In the first case process $P_1$ writes before $P_0$, in the second case the order is inverted.\relax }}{14}{figure.caption.9}}
\newlabel{figure: false-sharing}{{2.6}{14}{In this case false sharing of block two in the file can lead to two different outcomes. In the first case process $P_1$ writes before $P_0$, in the second case the order is inverted.\relax }{figure.caption.9}{}}
\citation{Mack11}
\citation{Grochowski1996}
\citation{NIST}
\citation{Masakatsu2015}
\citation{jacobson1991}
\citation{Worthington1994}
\citation{Iyer2001}
\citation{Shiroishi2009}
\citation{Shiroishi2009}
\citation{ASCAC2010}
\citation{HEP2015}
\citation{BES2015}
\citation{FES2016}
\citation{BER2016}
\citation{NP2016}
\citation{ASCAC2010}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}I/O Gap}{15}{subsection.2.1.2}}
\citation{Wang2013}
\citation{Zhang2015}
\citation{Breitwisch2008}
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces Recording density has been improved thanks to technological advancements in different fields including magnetic sensors and recording mediai~\cite  {Shiroishi2009}.\relax }}{16}{figure.caption.10}}
\newlabel{figure: hdd-trend}{{2.7}{16}{Recording density has been improved thanks to technological advancements in different fields including magnetic sensors and recording mediai~\cite {Shiroishi2009}.\relax }{figure.caption.10}{}}
\citation{Nieuwejaar1996}
\citation{Simitci1998}
\@writefile{lot}{\contentsline {table}{\numberline {2.1}{\ignorespaces Potential Exascale Computer Design for 2018 and its relationship to current HPC designs.\relax }}{17}{table.caption.11}}
\newlabel{table: hpc-trend}{{2.1}{17}{Potential Exascale Computer Design for 2018 and its relationship to current HPC designs.\relax }{table.caption.11}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.3}Small I/O}{17}{subsection.2.1.3}}
\citation{delRosario1993}
\@writefile{lof}{\contentsline {figure}{\numberline {2.8}{\ignorespaces Example of two-dimensional domain partitioning in parallel applications. The original domain is divided among four processes using a cyclic-cyclic partitioning strategy. Each process in the application performs its tasks on the data and then writes the results to a shared file concurrently.\relax }}{18}{figure.caption.12}}
\newlabel{figure: small-io}{{2.8}{18}{Example of two-dimensional domain partitioning in parallel applications. The original domain is divided among four processes using a cyclic-cyclic partitioning strategy. Each process in the application performs its tasks on the data and then writes the results to a shared file concurrently.\relax }{figure.caption.12}{}}
\citation{Bent2009}
\citation{ThakurC96}
\citation{Lofstead2008}
\citation{Schroeder2006}
\citation{Schroeder2007}
\citation{Michalak2005}
\citation{Daly2006}
\citation{Moody2010}
\citation{Moody2010_2}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.4}Checkpointing}{19}{subsection.2.1.4}}
\citation{Lamport1978}
\citation{Patil2011}
\citation{Sinnamohideen2010}
\citation{Congiu2012}
\newlabel{figure: checkpoint-n-n}{{2.9a}{20}{N-N pattern.\relax }{figure.caption.13}{}}
\newlabel{sub@figure: checkpoint-n-n}{{a}{20}{N-N pattern.\relax }{figure.caption.13}{}}
\newlabel{figure: checkpoint-n-1}{{2.9b}{20}{N-1 strided pattern.\relax }{figure.caption.13}{}}
\newlabel{sub@figure: checkpoint-n-1}{{b}{20}{N-1 strided pattern.\relax }{figure.caption.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.9}{\ignorespaces Common checkpoint patterns in HPC.\relax }}{20}{figure.caption.13}}
\newlabel{figure: checkpoint}{{2.9}{20}{Common checkpoint patterns in HPC.\relax }{figure.caption.13}{}}
\citation{Bent2009}
\citation{Frings2009}
\citation{Moody2010_2}
\citation{Ansel2009}
\citation{Wang2007}
\citation{Kaiser2016}
\citation{Arya2016}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Memory Technologies}{21}{section.2.2}}
\newlabel{section: mem-tech}{{2.2}{21}{Memory Technologies}{section.2.2}{}}
\citation{Ruemmler1994}
\@writefile{lof}{\contentsline {figure}{\numberline {2.10}{\ignorespaces Classical memory hierarchy in a standard computer. In the figure the dashed boxes represent existing and emerging solid state devices like SSDs and SCMs.\relax }}{22}{figure.caption.14}}
\newlabel{figure: io-gap}{{2.10}{22}{Classical memory hierarchy in a standard computer. In the figure the dashed boxes represent existing and emerging solid state devices like SSDs and SCMs.\relax }{figure.caption.14}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Magnetic Disks}{22}{subsection.2.2.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.11}{\ignorespaces Schematic representation of the components of a hard disk drive.\relax }}{23}{figure.caption.15}}
\newlabel{figure: hdd}{{2.11}{23}{Schematic representation of the components of a hard disk drive.\relax }{figure.caption.15}{}}
\citation{Masuoka1984}
\newlabel{formula: disk-access-time}{{2.3}{24}{Magnetic Disks}{equation.2.2.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Solid State Drives}{24}{subsection.2.2.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.12}{\ignorespaces High-level architecture of a flash based solid state drive.\relax }}{25}{figure.caption.16}}
\newlabel{figure: flash-ssd}{{2.12}{25}{High-level architecture of a flash based solid state drive.\relax }{figure.caption.16}{}}
\citation{Margaglia2015}
\citation{Wang2013}
\citation{Zhang2015}
\citation{Breitwisch2008}
\citation{Lee2009}
\citation{Xu2016}
\citation{Katzburg2016}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3}Storage Class Memories}{27}{subsection.2.2.3}}
\citation{Bovet2008}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Caching}{28}{section.2.3}}
\newlabel{section: caching}{{2.3}{28}{Caching}{section.2.3}{}}
\citation{Liao2005}
\citation{mpispecs}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Readahead and LRU}{29}{subsection.2.3.1}}
\citation{ChenR10}
\citation{shorter2003}
\@writefile{lof}{\contentsline {figure}{\numberline {2.13}{\ignorespaces Effect of readahead on a program that reads sequentially blocks of data from a file in the disk. In the example, every data block $Blk_i$ is read and afterwards processed $P(Blk_i)$ by the application. Readahead can merge the reading of two adjacent blocks amortizing the disk latency.\relax }}{30}{figure.caption.17}}
\newlabel{figure: readahead}{{2.13}{30}{Effect of readahead on a program that reads sequentially blocks of data from a file in the disk. In the example, every data block $Blk_i$ is read and afterwards processed $P(Blk_i)$ by the application. Readahead can merge the reading of two adjacent blocks amortizing the disk latency.\relax }{figure.caption.17}{}}
\citation{Bovet2008}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Prefetching}{31}{subsection.2.3.2}}
\citation{Chang2001}
\@writefile{lof}{\contentsline {figure}{\numberline {2.14}{\ignorespaces Effect of increased storage bandwidth on prefetching performance.\relax }}{32}{figure.caption.18}}
\newlabel{figure: prefetching}{{2.14}{32}{Effect of increased storage bandwidth on prefetching performance.\relax }{figure.caption.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.15}{\ignorespaces Effect of limited cache space on prefetching performance.\relax }}{34}{figure.caption.19}}
\newlabel{figure: prefetching_2}{{2.15}{34}{Effect of limited cache space on prefetching performance.\relax }{figure.caption.19}{}}
\@writefile{toc}{\contentsline {subsubsection}{Automatic Prefetching}{34}{figure.caption.19}}
\citation{Mowry1996}
\citation{Brown2001}
\citation{Bailey1991}
\citation{Brown2000}
\@writefile{toc}{\contentsline {paragraph}{Static}{35}{figure.caption.19}}
\citation{ChangG99}
\citation{Patterson1995}
\@writefile{toc}{\contentsline {paragraph}{Speculative}{36}{figure.caption.19}}
\citation{ChenBSTG08}
\citation{Liao2005}
\citation{TranR04}
\citation{Simitci1999}
\citation{Newbold1983}
\citation{HeBTAGGMCS13}
\citation{Byna2008}
\@writefile{toc}{\contentsline {subsubsection}{Dynamic History-based Prefetching}{38}{figure.caption.19}}
\citation{Folk99}
\citation{HEST12}
\citation{li2003}
\citation{Patterson1995}
\citation{VanDeBogartFK09}
\@writefile{toc}{\contentsline {subsubsection}{Manual Prefetching}{39}{figure.caption.19}}
\citation{Wang2004}
\citation{Kim2010}
\citation{CarnsHABLLR11}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.3}Write Behind}{40}{subsection.2.3.3}}
\citation{Iskra2008}
\citation{Liu2012}
\citation{Wang2014}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.4}Burst Buffers}{41}{subsection.2.3.4}}
\citation{mpispecs}
\citation{mpispecs}
\@writefile{lof}{\contentsline {figure}{\numberline {2.16}{\ignorespaces High-level architecture of an alternative HPC storage system design that uses I/O nodes to decouple compute from parallel file system access.\relax }}{42}{figure.caption.20}}
\newlabel{figure: hpc-io-nodes}{{2.16}{42}{High-level architecture of an alternative HPC storage system design that uses I/O nodes to decouple compute from parallel file system access.\relax }{figure.caption.20}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}I/O Middlewares}{42}{section.2.4}}
\newlabel{section: middlewares}{{2.4}{42}{I/O Middlewares}{section.2.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.1}MPI-IO}{42}{subsection.2.4.1}}
\citation{ThakurGL96}
\citation{Ying08}
\citation{ProstTHKW00}
\citation{kotz1994}
\citation{Panda1995}
\citation{delRosario1993}
\citation{Bordawekar1993}
\citation{ThakurC96}
\@writefile{toc}{\contentsline {subsubsection}{The ROMIO Middleware}{44}{subsection.2.4.1}}
\@writefile{toc}{\contentsline {paragraph}{Collective I/O}{44}{subsection.2.4.1}}
\citation{Bent2009}
\@writefile{lof}{\contentsline {figure}{\numberline {2.17}{\ignorespaces Simplified two phase I/O scheme. A two-dimensional domain is partitioned among four processes in the parallel application using a column-block strategy. Data is then rearranged to form an intermediate pattern that matches the logical data organization in the file. This pattern is afterwards used by the two aggregators to access the storage system.\relax }}{45}{figure.caption.21}}
\newlabel{figure: coll_io}{{2.17}{45}{Simplified two phase I/O scheme. A two-dimensional domain is partitioned among four processes in the parallel application using a column-block strategy. Data is then rearranged to form an intermediate pattern that matches the logical data organization in the file. This pattern is afterwards used by the two aggregators to access the storage system.\relax }{figure.caption.21}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.2}Parallel Log structured File System}{45}{subsection.2.4.2}}
\citation{Adam2011}
\citation{Welch2004}
\@writefile{lof}{\contentsline {figure}{\numberline {2.18}{\ignorespaces Pictorial representation of the PLFS translation mechanism that converts original application N-1 patterns into N-N patterns.\relax }}{46}{figure.caption.22}}
\newlabel{figure: plfs}{{2.18}{46}{Pictorial representation of the PLFS translation mechanism that converts original application N-1 patterns into N-N patterns.\relax }{figure.caption.22}{}}
\citation{Moody2010_2}
\citation{Moody2010}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.3}Scalable Checkpoint Restart Library}{47}{subsection.2.4.3}}
\citation{Frings2009}
\citation{Freche2009}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.4}SIONlib}{48}{subsection.2.4.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.19}{\ignorespaces Simplified representation of the SIONlib translation mechanism. A large number of task-local files is mapped into a smaller number of multifiles.\relax }}{48}{figure.caption.23}}
\newlabel{figure: sionlib}{{2.19}{48}{Simplified representation of the SIONlib translation mechanism. A large number of task-local files is mapped into a smaller number of multifiles.\relax }{figure.caption.23}{}}
\citation{Lofstead2008}
\citation{Liu2014}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.5}Adaptable I/O System}{49}{subsection.2.4.5}}
\citation{Braam02}
\citation{SchmuckH02}
\citation{ThakurGL99}
\citation{Ying08}
\citation{ProstTHKW00}
\citation{CarnsHABLLR11}
\citation{ChingCLP06}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Guided Prefetching in Linux}{51}{chapter.3}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chapt: prefetching}{{3}{51}{Guided Prefetching in Linux}{chapter.3}{}}
\citation{Congiu2014}
\citation{Congiu2017}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}File System Prefetching Intefaces}{53}{section.3.1}}
\newlabel{section: hints_interface}{{3.1}{53}{File System Prefetching Intefaces}{section.3.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}POSIX Advice}{54}{subsection.3.1.1}}
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces Values for \textit  {advice} in the \textit  {posix\_fadvise()} system call\relax }}{54}{table.caption.24}}
\newlabel{table: advice_table}{{3.1}{54}{Values for \textit {advice} in the \textit {posix\_fadvise()} system call\relax }{table.caption.24}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}GPFS Hints}{55}{subsection.3.1.2}}
\@writefile{lot}{\contentsline {table}{\numberline {3.2}{\ignorespaces GPFS hint data structures\relax }}{55}{table.caption.25}}
\newlabel{table: gpfs_hints_table}{{3.2}{55}{GPFS hint data structures\relax }{table.caption.25}{}}
\newlabel{mar}{{3.1}{56}{Multiple Access Range Hint Data Structure}{lstlisting.3.1}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {3.1}Multiple Access Range Hint Data Structure}{56}{lstlisting.3.1}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}The Mercury Middleware}{56}{section.3.2}}
\newlabel{section: mercury_concept}{{3.2}{56}{The Mercury Middleware}{section.3.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Mercury I/O software stack. \textit  {assisted I/O library} and \textit  {advice manager} communicate through UNIX domain sockets. The AM binds its socket to the local file system pathname \texttt  {/tmp/channel}, while the AIO connects its socket to the same pathname; exactly in the same way they would bind and connect to an IP address if they were located on different nodes in the network. Unix domain sockets are used to pass ancillary data as well as custom messages between the two software entities. Data can reside in a local Linux file system, in Lustre or in GPFS.\relax }}{57}{figure.caption.26}}
\newlabel{figure: softwarestack}{{3.1}{57}{Mercury I/O software stack. \textit {assisted I/O library} and \textit {advice manager} communicate through UNIX domain sockets. The AM binds its socket to the local file system pathname \texttt {/tmp/channel}, while the AIO connects its socket to the same pathname; exactly in the same way they would bind and connect to an IP address if they were located on different nodes in the network. Unix domain sockets are used to pass ancillary data as well as custom messages between the two software entities. Data can reside in a local Linux file system, in Lustre or in GPFS.\relax }{figure.caption.26}{}}
\citation{StevensR13}
\citation{UnixSock}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Interprocess Communication}{58}{subsection.3.2.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Detailed architecture for the \textit  {Advice Manager} (AM) component. This can be further divided into three blocks: \textit  {Request Manager} (RM), \textit  {Register Log} (RL), and \textit  {Advisor Thread} (AT).\relax }}{59}{figure.caption.27}}
\newlabel{figure: architecture}{{3.2}{59}{Detailed architecture for the \textit {Advice Manager} (AM) component. This can be further divided into three blocks: \textit {Request Manager} (RM), \textit {Register Log} (RL), and \textit {Advisor Thread} (AT).\relax }{figure.caption.27}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}File Data Prefetching}{59}{subsection.3.2.2}}
\newlabel{config}{{3.2}{60}{Example of Json Configuration File}{lstlisting.3.2}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {3.2}Example of Json Configuration File}{60}{lstlisting.3.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.3}POSIX Advice integration with Lustre}{61}{subsection.3.2.3}}
\citation{TranR04}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Simplified function call graph for the read operation in Lustre. For page operations in the Linux kernel the picture also shows the call graph typically followed by local reads as well as the call graph for the \texttt  {POSIX\_FADV\_WILLNEED} advice in the \texttt  {posix\_fadvise()} implementation (dashed line).\relax }}{63}{figure.caption.28}}
\newlabel{figure: kernel}{{3.3}{63}{Simplified function call graph for the read operation in Lustre. For page operations in the Linux kernel the picture also shows the call graph typically followed by local reads as well as the call graph for the \texttt {POSIX\_FADV\_WILLNEED} advice in the \texttt {posix\_fadvise()} implementation (dashed line).\relax }{figure.caption.28}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Contributions}{63}{section.3.3}}
\newlabel{section: mercury_related_work}{{3.3}{63}{Contributions}{section.3.3}{}}
\citation{HeBTAGGMCS13}
\citation{ChangG99}
\citation{Mowry1996}
\citation{Brown2000}
\citation{Brown2001}
\citation{ChenBSTG08}
\citation{Byna2008}
\citation{ChenR10}
\citation{HEST12}
\citation{VanDeBogartFK09}
\citation{ProstTHJK01}
\citation{ChingCLP06}
\citation{HeSSYT11}
\citation{ThakurGL99}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}NVM Based Write-behind Caching}{66}{chapter.4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chapt: checkpointing}{{4}{66}{NVM Based Write-behind Caching}{chapter.4}{}}
\citation{ASCAC2010}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Extended Two Phase Algorithm}{67}{section.4.1}}
\newlabel{sec: ext2ph}{{4.1}{67}{Extended Two Phase Algorithm}{section.4.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Collective I/O flow diagram for the write path in aggregators (non-aggregators neither receive nor write any data, just send it to aggregators). \texttt  {MPI\_File\_write\_all()} invokes \texttt  {ADIOI\_GEN\_WriteStridedColl()}. Performance critical functions for the collective I/O branch are highlighted in grey.\relax }}{68}{figure.caption.29}}
\newlabel{figure: coll_io_impl}{{4.1}{68}{Collective I/O flow diagram for the write path in aggregators (non-aggregators neither receive nor write any data, just send it to aggregators). \codeword {MPI\_File\_write\_all()} invokes \codeword {ADIOI\_GEN\_WriteStridedColl()}. Performance critical functions for the collective I/O branch are highlighted in grey.\relax }{figure.caption.29}{}}
\newlabel{formula: aggr-region}{{4.1}{69}{Extended Two Phase Algorithm}{equation.4.1.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces Collective I/O hints in ROMIO.\relax }}{70}{table.caption.30}}
\newlabel{table: coll_io_hints_table}{{4.1}{70}{Collective I/O hints in ROMIO.\relax }{table.caption.30}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Collective I/O Limitations}{71}{section.4.2}}
\newlabel{sec: coll_io_limit}{{4.2}{71}{Collective I/O Limitations}{section.4.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}File System Stripe Contention}{71}{subsection.4.2.1}}
\newlabel{figure: gpfs-lock}{{4.2a}{72}{\relax }{figure.caption.31}{}}
\newlabel{sub@figure: gpfs-lock}{{a}{72}{\relax }{figure.caption.31}{}}
\newlabel{figure: lustre-lock}{{4.2b}{72}{\relax }{figure.caption.31}{}}
\newlabel{sub@figure: lustre-lock}{{b}{72}{\relax }{figure.caption.31}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Extent based locking for GPFS~\ref  {figure: gpfs-lock} and Lustre~\ref  {figure: lustre-lock}. In both figures there are three process requesting access to different parts of the file at different times.\relax }}{72}{figure.caption.31}}
\newlabel{figure: gpfs-partition}{{4.3a}{73}{\relax }{figure.caption.32}{}}
\newlabel{sub@figure: gpfs-partition}{{a}{73}{\relax }{figure.caption.32}{}}
\newlabel{figure: lustre-partition}{{4.3b}{73}{\relax }{figure.caption.32}{}}
\newlabel{sub@figure: lustre-partition}{{b}{73}{\relax }{figure.caption.32}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Possible partitioning strategies for GPFS~\ref  {figure: gpfs-partition} and Lustre~\ref  {figure: lustre-partition}. File domains, and thus aggregators, are marked with different filling patterns.\relax }}{73}{figure.caption.32}}
\citation{LiaoA08}
\citation{Liao11}
\citation{Zhang2009}
\citation{Chen2011}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}Logical to Physical Layout Mismatch}{74}{subsection.4.2.2}}
\citation{Ching2002}
\citation{Ching2003}
\citation{Filgueira2008}
\citation{ASCAC2010}
\citation{Lu2012}
\citation{Lu2013}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces Ideal configuration of processes, I/O servers and data distribution in the system.\relax }}{75}{figure.caption.33}}
\newlabel{figure: resonant-io}{{4.4}{75}{Ideal configuration of processes, I/O servers and data distribution in the system.\relax }{figure.caption.33}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.3}Memory Pressure}{75}{subsection.4.2.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.4}Network Concurrency}{76}{subsection.4.2.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces Effect of I/O server scheduling strategies on collective I/O performance. Three examples are shown, in the first every aggregator reads from a different I/O server; in the second three aggregators read from the same I/O server, which does not perform any scheduling optimization; and in the third three aggregators read from the same I/O server, which this time does perform a scheduling optimization.\relax }}{77}{figure.caption.34}}
\newlabel{figure: network-concur}{{4.5}{77}{Effect of I/O server scheduling strategies on collective I/O performance. Three examples are shown, in the first every aggregator reads from a different I/O server; in the second three aggregators read from the same I/O server, which does not perform any scheduling optimization; and in the third three aggregators read from the same I/O server, which this time does perform a scheduling optimization.\relax }{figure.caption.34}{}}
\citation{Liu2013}
\citation{Sehrish2013}
\citation{Yu08}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.5}Global Synchronization Overhead}{78}{subsection.4.2.5}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces Six processes are collaborating in collective I/O. Because $P_0$, $P_1$ and $P_2$ do not exchange data with other processes there is no need for them to communicate data shuffling information to $P_3$, $P_4$ and $P_5$ during two phase I/O rounds.\relax }}{79}{figure.caption.35}}
\newlabel{figure: parcol}{{4.6}{79}{Six processes are collaborating in collective I/O. Because $P_0$, $P_1$ and $P_2$ do not exchange data with other processes there is no need for them to communicate data shuffling information to $P_3$, $P_4$ and $P_5$ during two phase I/O rounds.\relax }{figure.caption.35}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}A Non-Volatile Memory Based Approach}{79}{section.4.3}}
\newlabel{sec: nvm-approach}{{4.3}{79}{A Non-Volatile Memory Based Approach}{section.4.3}{}}
\newlabel{list: lustre_table}{{4.1}{80}{Operation table for Lustre driver}{lstlisting.4.1}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {4.1}Operation table for Lustre driver.}{80}{lstlisting.4.1}}
\newlabel{figure: romio-architecture}{{4.7a}{81}{\relax }{figure.caption.36}{}}
\newlabel{sub@figure: romio-architecture}{{a}{81}{\relax }{figure.caption.36}{}}
\newlabel{figure: new-romio-architecture}{{4.7b}{81}{\relax }{figure.caption.36}{}}
\newlabel{sub@figure: new-romio-architecture}{{b}{81}{\relax }{figure.caption.36}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.7}{\ignorespaces Original ROMIO architecture (\ref  {figure: romio-architecture}) and proposed ROMIO architecture (\ref  {figure: new-romio-architecture}).\relax }}{81}{figure.caption.36}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}MPI-IO Hints Extensions}{82}{subsection.4.3.1}}
\@writefile{lot}{\contentsline {table}{\numberline {4.2}{\ignorespaces Proposed MPI-IO hints extensions.\relax }}{82}{table.caption.37}}
\newlabel{table: hints_table}{{4.2}{82}{Proposed MPI-IO hints extensions.\relax }{table.caption.37}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.2}Cache Hints Integration in ROMIO}{83}{subsection.4.3.2}}
\citation{mpispecs}
\@writefile{toc}{\contentsline {subsubsection}{Cache Synchronization Thread}{84}{figure.caption.38}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.8}{\ignorespaces Cache plugin class diagram. The synchronization thread \texttt  {ADIOI\_Sync\_thread\_t} serves synchronization requests of type \texttt  {ADIOI\_Sync\_req\_t}.\relax }}{85}{figure.caption.38}}
\newlabel{figure: cache-plugin-class}{{4.8}{85}{Cache plugin class diagram. The synchronization thread \codeword {ADIOI\_Sync\_thread\_t} serves synchronization requests of type \codeword {ADIOI\_Sync\_req\_t}.\relax }{figure.caption.38}{}}
\@writefile{toc}{\contentsline {subsubsection}{Cache Synchronization Request}{86}{figure.caption.38}}
\@writefile{toc}{\contentsline {subsubsection}{Atomic Queue}{86}{figure.caption.38}}
\@writefile{toc}{\contentsline {subsubsection}{Collective Write Caching}{87}{figure.caption.38}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.9}{\ignorespaces Extended collective I/O flow diagram including cache plugin support.\relax }}{88}{figure.caption.39}}
\newlabel{figure: coll_io_cache}{{4.9}{88}{Extended collective I/O flow diagram including cache plugin support.\relax }{figure.caption.39}{}}
\citation{ColomaCWWRP04}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.3}BeeGFS Cache Integration in ROMIO}{89}{subsection.4.3.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.4}Consistency Semantics}{89}{subsection.4.3.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.5}Changes to the Application's Workflow}{91}{subsection.4.3.5}}
\@writefile{toc}{\contentsline {subsubsection}{MPIWRAP Library}{91}{figure.caption.40}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.10}{\ignorespaces Standard and modified workflows. When cache is disabled compute phase `k+1' starts after file `k' has been closed. When the cache is enabled compute `k+1' can start immediately after data has been written. At the same time, background synchronization of cached data starts. File `k' is closed before the file `k+1' is opened, forcing the implementation to wait for cache synchronization to complete.\relax }}{92}{figure.caption.40}}
\newlabel{figure: workflow}{{4.10}{92}{Standard and modified workflows. When cache is disabled compute phase `k+1' starts after file `k' has been closed. When the cache is enabled compute `k+1' can start immediately after data has been written. At the same time, background synchronization of cached data starts. File `k' is closed before the file `k+1' is opened, forcing the implementation to wait for cache synchronization to complete.\relax }{figure.caption.40}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.6}Write Bandwidth}{92}{subsection.4.3.6}}
\newlabel{formula: bw}{{4.2}{92}{Write Bandwidth}{equation.4.3.2}{}}
\newlabel{formula: abw}{{4.3}{92}{Write Bandwidth}{equation.4.3.3}{}}
\citation{Yu08}
\citation{Lofstead2008}
\citation{Lu2012}
\citation{Lu2013}
\citation{Liao11}
\citation{Chen2011}
\citation{Zhang2009}
\citation{Liu2013}
\citation{Yu2007}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Contributions}{93}{section.4.4}}
\newlabel{sec: nvm-related}{{4.4}{93}{Contributions}{section.4.4}{}}
\citation{LeeRTXW04}
\citation{XiaosongWLS03}
\citation{Moody2010}
\citation{Moody2010_2}
\citation{DorierACSO12}
\citation{Lofstead2016}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Evaluation}{96}{chapter.5}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chapt: evaluation}{{5}{96}{Evaluation}{chapter.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}I/O Prefetching in ROOT}{96}{section.5.1}}
\newlabel{figure: iopat_profile}{{5.1a}{97}{\textit {}\relax }{figure.caption.41}{}}
\newlabel{sub@figure: iopat_profile}{{a}{97}{\textit {}\relax }{figure.caption.41}{}}
\newlabel{figure: iopat_zoom}{{5.1b}{97}{\textit {}\relax }{figure.caption.41}{}}
\newlabel{sub@figure: iopat_zoom}{{b}{97}{\textit {}\relax }{figure.caption.41}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces I/O read profile of the target application under analysis (\ref  {figure: iopat_profile}), extracted from the the GPFS file system in the test cluster, and zoomed window (\ref  {figure: iopat_zoom}) showing the actual pattern details.\relax }}{97}{figure.caption.41}}
\newlabel{figure: iopattern_with_statistics}{{5.1}{97}{I/O read profile of the target application under analysis (\ref {figure: iopat_profile}), extracted from the the GPFS file system in the test cluster, and zoomed window (\ref {figure: iopat_zoom}) showing the actual pattern details.\relax }{figure.caption.41}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces Comparison between different usage stategies of posix\_fadvise for an input file of 55 GB residing in an ext4 file system. The first bar represents the case in which no advice is used, the second bar represents the case in which a POSIX\_FADV\_WILLNEED is issued for the whole file at the beginning of the application and the third bar represents the case in which POSIX\_FADV\_WILLNEED is issued using Mercury.\relax }}{99}{figure.caption.42}}
\newlabel{figure: fadvise_comparison}{{5.2}{99}{Comparison between different usage stategies of posix\_fadvise for an input file of 55 GB residing in an ext4 file system. The first bar represents the case in which no advice is used, the second bar represents the case in which a POSIX\_FADV\_WILLNEED is issued for the whole file at the beginning of the application and the third bar represents the case in which POSIX\_FADV\_WILLNEED is issued using Mercury.\relax }{figure.caption.42}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.1}Test Bed}{99}{subsection.5.1.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.2}Performance Results}{100}{subsection.5.1.2}}
\newlabel{figure: ext4_1}{{5.3a}{102}{\textit {}\relax }{figure.caption.43}{}}
\newlabel{sub@figure: ext4_1}{{a}{102}{\textit {}\relax }{figure.caption.43}{}}
\newlabel{figure: gpfs_1}{{5.3b}{102}{\textit {}\relax }{figure.caption.43}{}}
\newlabel{sub@figure: gpfs_1}{{b}{102}{\textit {}\relax }{figure.caption.43}{}}
\newlabel{figure: lustre_1}{{5.3c}{102}{\textit {}\relax }{figure.caption.43}{}}
\newlabel{sub@figure: lustre_1}{{c}{102}{\textit {}\relax }{figure.caption.43}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.3}{\ignorespaces Running time of the ROOT application for the three file systems under study using different input file sized (\ref  {figure: ext4_1},~\ref  {figure: gpfs_1} and~\ref  {figure: lustre_1}).\relax }}{102}{figure.caption.43}}
\newlabel{figure: run-time_1}{{5.3}{102}{Running time of the ROOT application for the three file systems under study using different input file sized (\ref {figure: ext4_1},~\ref {figure: gpfs_1} and~\ref {figure: lustre_1}).\relax }{figure.caption.43}{}}
\newlabel{figure: ext4_2}{{5.4a}{103}{\textit {}\relax }{figure.caption.44}{}}
\newlabel{sub@figure: ext4_2}{{a}{103}{\textit {}\relax }{figure.caption.44}{}}
\newlabel{figure: gpfs_2}{{5.4b}{103}{\textit {}\relax }{figure.caption.44}{}}
\newlabel{sub@figure: gpfs_2}{{b}{103}{\textit {}\relax }{figure.caption.44}{}}
\newlabel{figure: lustre_2}{{5.4c}{103}{\textit {}\relax }{figure.caption.44}{}}
\newlabel{sub@figure: lustre_2}{{c}{103}{\textit {}\relax }{figure.caption.44}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.4}{\ignorespaces Running time of the ROOT application for the three file system under study using different of application instances accessing a file of 5 GB (\ref  {figure: ext4_2},~\ref  {figure: gpfs_2} and~\ref  {figure: lustre_2}).\relax }}{103}{figure.caption.44}}
\newlabel{figure: run-time_2}{{5.4}{103}{Running time of the ROOT application for the three file system under study using different of application instances accessing a file of 5 GB (\ref {figure: ext4_2},~\ref {figure: gpfs_2} and~\ref {figure: lustre_2}).\relax }{figure.caption.44}{}}
\newlabel{figure: ext4_3}{{5.5a}{104}{\textit {}\relax }{figure.caption.45}{}}
\newlabel{sub@figure: ext4_3}{{a}{104}{\textit {}\relax }{figure.caption.45}{}}
\newlabel{figure: gpfs_3}{{5.5b}{104}{\textit {}\relax }{figure.caption.45}{}}
\newlabel{sub@figure: gpfs_3}{{b}{104}{\textit {}\relax }{figure.caption.45}{}}
\newlabel{figure: lustre_3}{{5.5c}{104}{\textit {}\relax }{figure.caption.45}{}}
\newlabel{sub@figure: lustre_3}{{c}{104}{\textit {}\relax }{figure.caption.45}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.5}{\ignorespaces Reads processed by local ext4, GPFS and Lustre I/O servers for various input file sizes (\ref  {figure: ext4_3},~\ref  {figure: gpfs_3} and~\ref  {figure: lustre_3}).\relax }}{104}{figure.caption.45}}
\newlabel{figure: read_1}{{5.5}{104}{Reads processed by local ext4, GPFS and Lustre I/O servers for various input file sizes (\ref {figure: ext4_3},~\ref {figure: gpfs_3} and~\ref {figure: lustre_3}).\relax }{figure.caption.45}{}}
\newlabel{figure: ext4_4}{{5.6a}{105}{\textit {}\relax }{figure.caption.46}{}}
\newlabel{sub@figure: ext4_4}{{a}{105}{\textit {}\relax }{figure.caption.46}{}}
\newlabel{figure: gpfs_4}{{5.6b}{105}{\textit {}\relax }{figure.caption.46}{}}
\newlabel{sub@figure: gpfs_4}{{b}{105}{\textit {}\relax }{figure.caption.46}{}}
\newlabel{figure: lustre_4}{{5.6c}{105}{\textit {}\relax }{figure.caption.46}{}}
\newlabel{sub@figure: lustre_4}{{c}{105}{\textit {}\relax }{figure.caption.46}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.6}{\ignorespaces Reads processed by local ext4, GPFS and Lustre I/O servers for multiple instances of ROOT accessing a file of 5 GB (\ref  {figure: ext4_4},~\ref  {figure: gpfs_4} and~\ref  {figure: lustre_4}).\relax }}{105}{figure.caption.46}}
\newlabel{figure: read_2}{{5.6}{105}{Reads processed by local ext4, GPFS and Lustre I/O servers for multiple instances of ROOT accessing a file of 5 GB (\ref {figure: ext4_4},~\ref {figure: gpfs_4} and~\ref {figure: lustre_4}).\relax }{figure.caption.46}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.3}Conclusions}{106}{subsection.5.1.3}}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Write Behind in Collective I/O}{106}{section.5.2}}
\citation{Gropp2014}
\citation{Eicker2013}
\citation{Mcpeek2002}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.1}Testbed}{107}{subsection.5.2.1}}
\citation{Bordawekar1993}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.2}Performance Results}{108}{subsection.5.2.2}}
\@writefile{toc}{\contentsline {subsubsection}{Coll\_perf}{108}{subsection.5.2.2}}
\newlabel{figure: collperf-bw}{{5.7a}{109}{\relax }{figure.caption.47}{}}
\newlabel{sub@figure: collperf-bw}{{a}{109}{\relax }{figure.caption.47}{}}
\newlabel{figure: collperf-elaps-disable}{{5.7b}{109}{\relax }{figure.caption.47}{}}
\newlabel{sub@figure: collperf-elaps-disable}{{b}{109}{\relax }{figure.caption.47}{}}
\newlabel{figure: collperf-elaps-enable}{{5.7c}{109}{\relax }{figure.caption.47}{}}
\newlabel{sub@figure: collperf-elaps-enable}{{c}{109}{\relax }{figure.caption.47}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.7}{\ignorespaces Perceived and theoretical write bandwidth for all combinations of aggregators and collective buffer sizes (\ref  {figure: collperf-bw}); collective I/O contribution breakdown when cache is disabled (\ref  {figure: collperf-elaps-disable}); collective I/O contribution breakdown when cache is enabled (\ref  {figure: collperf-elaps-enable}).\relax }}{109}{figure.caption.47}}
\newlabel{figure: collperf-results}{{5.7}{109}{Perceived and theoretical write bandwidth for all combinations of aggregators and collective buffer sizes (\ref {figure: collperf-bw}); collective I/O contribution breakdown when cache is disabled (\ref {figure: collperf-elaps-disable}); collective I/O contribution breakdown when cache is enabled (\ref {figure: collperf-elaps-enable}).\relax }{figure.caption.47}{}}
\citation{Rosner2000}
\@writefile{toc}{\contentsline {subsubsection}{Flash-IO}{111}{figure.caption.47}}
\newlabel{figure: flash-bw}{{5.8a}{112}{\relax }{figure.caption.48}{}}
\newlabel{sub@figure: flash-bw}{{a}{112}{\relax }{figure.caption.48}{}}
\newlabel{figure: flash-elaps-disable}{{5.8b}{112}{\relax }{figure.caption.48}{}}
\newlabel{sub@figure: flash-elaps-disable}{{b}{112}{\relax }{figure.caption.48}{}}
\newlabel{figure: flash-elaps-enable}{{5.8c}{112}{\relax }{figure.caption.48}{}}
\newlabel{sub@figure: flash-elaps-enable}{{c}{112}{\relax }{figure.caption.48}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.8}{\ignorespaces Perceived I/O bandwidth for all combinations of aggregators and collective buffer sizes (\ref  {figure: flash-bw}); collective I/O contribution breakdown when cache is disabled (\ref  {figure: flash-elaps-disable}); collective I/O contribution breakdown when cache is enabled (\ref  {figure: flash-elaps-enable}).\relax }}{112}{figure.caption.48}}
\newlabel{figure: flash-results}{{5.8}{112}{Perceived I/O bandwidth for all combinations of aggregators and collective buffer sizes (\ref {figure: flash-bw}); collective I/O contribution breakdown when cache is disabled (\ref {figure: flash-elaps-disable}); collective I/O contribution breakdown when cache is enabled (\ref {figure: flash-elaps-enable}).\relax }{figure.caption.48}{}}
\@writefile{toc}{\contentsline {subsubsection}{IOR}{113}{figure.caption.49}}
\newlabel{figure: ior-bw}{{5.9a}{114}{\relax }{figure.caption.49}{}}
\newlabel{sub@figure: ior-bw}{{a}{114}{\relax }{figure.caption.49}{}}
\newlabel{figure: ior-elaps-disable}{{5.9b}{114}{\relax }{figure.caption.49}{}}
\newlabel{sub@figure: ior-elaps-disable}{{b}{114}{\relax }{figure.caption.49}{}}
\newlabel{figure: ior-elaps-enable}{{5.9c}{114}{\relax }{figure.caption.49}{}}
\newlabel{sub@figure: ior-elaps-enable}{{c}{114}{\relax }{figure.caption.49}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.9}{\ignorespaces Perceived I/O bandwidth for all combinations of aggregators and collective buffer sizes (\ref  {figure: ior-bw}); collective I/O contribution breakdown when cache is disabled (\ref  {figure: ior-elaps-disable}); collective I/O contribution breakdown when cache is enabled (\ref  {figure: ior-elaps-enable}).\relax }}{114}{figure.caption.49}}
\newlabel{figure: ior-results}{{5.9}{114}{Perceived I/O bandwidth for all combinations of aggregators and collective buffer sizes (\ref {figure: ior-bw}); collective I/O contribution breakdown when cache is disabled (\ref {figure: ior-elaps-disable}); collective I/O contribution breakdown when cache is enabled (\ref {figure: ior-elaps-enable}).\relax }{figure.caption.49}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.3}Conclusions}{115}{subsection.5.2.3}}
\citation{VanDeBogartFK09}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Conclusions and Future Work}{116}{chapter.6}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chapt: conclusion}{{6}{116}{Conclusions and Future Work}{chapter.6}{}}
\citation{Zhang2009}
\citation{Freche2009}
\bibstyle{alpha}
\bibdata{bibliography}
\bibcite{Ansel2009}{AAC09}
\bibcite{Arya2016}{AGPC16}
\bibcite{Adam2011}{AJM{$^{+}$}11}
\bibcite{Andrews2015}{And15}
\bibcite{ASCAC2010}{ASC10}
\bibcite{Bailey1991}{BBLS91}
\bibcite{Bovet2008}{BC08}
\bibcite{Byna2008}{BCS{$^{+}$}08}
\bibcite{Bordawekar1993}{BdRC93}
\@writefile{toc}{\contentsline {chapter}{Bibliography}{119}{chapter.6}}
\bibcite{Bent2009}{BGG{$^{+}$}09}
\bibcite{Brown2000}{BM00}
\bibcite{Brown2001}{BMK01}
\bibcite{Braam02}{Bra02}
\bibcite{Breitwisch2008}{Bre08}
\bibcite{ChenBSTG08}{CBS{$^{+}$}08}
\bibcite{Ching2003}{CCC{$^{+}$}03}
\bibcite{Ching2002}{CCkL{$^{+}$}02}
\bibcite{ColomaCWWRP04}{CCL{$^{+}$}04}
\bibcite{ChingCLP06}{CCL{$^{+}$}06}
\bibcite{ChangG99}{CG99}
\bibcite{Chang2001}{CGML01}
\bibcite{Congiu2012}{CGNB12}
\bibcite{Congiu2014}{CGP{$^{+}$}14}
\bibcite{Congiu2017}{CGP{$^{+}$}17}
\bibcite{Chatrchyan2011}{Cha11a}
\bibcite{CarnsHABLLR11}{CHA{$^{+}$}11b}
\bibcite{CarnsLRT}{CLI{$^{+}$}00}
\bibcite{Congiu2016}{CNSB16}
\bibcite{ChenR10}{CR10}
\bibcite{Chen2011}{CST{$^{+}$}11}
\bibcite{DorierACSO12}{DAC{$^{+}$}12}
\bibcite{Daly2006}{Dal06}
\bibcite{Deca2013}{DLMM13}
\bibcite{delRosario1993}{dRBC93}
\bibcite{Eicker2013}{ELMS13}
\bibcite{BES2015}{Ene15}
\bibcite{BER2016}{ERA16}
\bibcite{Folk99}{FCY99}
\bibcite{Freche2009}{FFS09}
\bibcite{Fryxell2000}{FOR{$^{+}$}00}
\bibcite{Filgueira2008}{FSP{$^{+}$}08}
\bibcite{Frings2009}{FWP09}
\bibcite{Fan2004}{FXM04}
\bibcite{Grochowski1996}{GH96}
\bibcite{Gray2006}{GL06}
\bibcite{Gropp2014}{GLS14}
\bibcite{Gray1981}{Gra81}
\bibcite{HeBTAGGMCS13}{HBT{$^{+}$}13}
\bibcite{HeSSYT11}{HSS{$^{+}$}11}
\bibcite{HEST12}{HST12}
\bibcite{Iyer2001}{ID01}
\bibcite{Iskra2008}{IRYB08}
\bibcite{Isaac2013}{Isa13}
\bibcite{jacobson1991}{JW91}
\bibcite{Kim2010}{KGS{$^{+}$}10}
\bibcite{Kaiser2016}{KGS{$^{+}$}16}
\bibcite{Katzburg2016}{KGW16}
\bibcite{Liao11}{kL11}
\bibcite{Liao2005}{kLCC{$^{+}$}05}
\bibcite{kotz1994}{Kot94}
\bibcite{Lamport1978}{Lam78}
\bibcite{LiaoA08}{LC08}
\bibcite{Liu2012}{LCC{$^{+}$}12}
\bibcite{Lu2012}{LCTZ12}
\bibcite{Liu2013}{LCZ13}
\bibcite{Lu2013}{LCZT13}
\bibcite{Lee2009}{LIMB09}
\bibcite{Lofstead2016}{LJM{$^{+}$}16}
\bibcite{li2003}{LkLC{$^{+}$}03}
\bibcite{Lofstead2008}{LKS{$^{+}$}08}
\bibcite{Liu2014}{LLT{$^{+}$}14}
\bibcite{LeeRTXW04}{LRT{$^{+}$}04}
\bibcite{Mack11}{Mac11}
\bibcite{Masuoka1984}{MAI{$^{+}$}84}
\bibcite{Margaglia2015}{MB15}
\bibcite{Moody2010}{MBMdS10}
\bibcite{Moody2010_2}{MBMS10}
\bibcite{Mcpeek2002}{Mcp02}
\bibcite{Mowry1996}{MDK96}
\bibcite{Michalak2005}{MHH{$^{+}$}05}
\bibcite{Masakatsu2015}{MHS15}
\bibcite{Markidis2010}{MLRu10}
\bibcite{mpispecs}{mpi12}
\bibcite{XiaosongWLS03}{MWLY03}
\bibcite{Newbold1983}{New83}
\bibcite{NIST}{NIS99}
\bibcite{Nieuwejaar1996}{NKP{$^{+}$}96}
\bibcite{Patil2011}{PG11}
\bibcite{Patterson1995}{PGG{$^{+}$}95}
\bibcite{Patterson1988}{PGK88}
\bibcite{HEP2015}{Phy15}
\bibcite{POSIX}{POS}
\bibcite{ProstTHKW00}{PTH{$^{+}$}00}
\bibcite{ProstTHJK01}{PTH{$^{+}$}01}
\bibcite{Rosner2000}{RCD{$^{+}$}00}
\bibcite{Ruemmler1994}{RW94}
\bibcite{Stamos1990}{SC90}
\bibcite{FES2016}{Sci16a}
\bibcite{NP2016}{Sci16b}
\bibcite{Panda1995}{SCJ{$^{+}$}95}
\bibcite{Shiroishi2009}{SFT{$^{+}$}09}
\bibcite{Schroeder2006}{SG06}
\bibcite{Schroeder2007}{SG07}
\bibcite{SchmuckH02}{SH02}
\bibcite{Sobhaninejad2011}{SHK11}
\bibcite{shorter2003}{Sho03}
\bibcite{Simitci1998}{SR98}
\bibcite{StevensR13}{SR13}
\bibcite{Simitci1999}{SRF{$^{+}$}99}
\bibcite{Sinnamohideen2010}{SSH{$^{+}$}10}
\bibcite{Sehrish2013}{SSL{$^{+}$}13}
\bibcite{ThakurC96}{TC96}
\bibcite{ThakurGL96}{TGL96}
\bibcite{ThakurGL99}{TGL99}
\bibcite{TranR04}{TR04}
\bibcite{UnixSock}{Uni}
\bibcite{VanDeBogartFK09}{VFK09}
\bibcite{Vital2013}{VGL{$^{+}$}13}
\bibcite{Wang2013}{WAA13}
\bibcite{Worthington1994}{WGP94}
\bibcite{Wang2007}{WMES07}
\bibcite{Wang2014}{WOW{$^{+}$}14}
\bibcite{Wright2007}{WSSZ07}
\bibcite{Welch2008}{WUA{$^{+}$}08}
\bibcite{Welch2004}{WWG04}
\bibcite{Wang2004}{WXH{$^{+}$}04}
\bibcite{Xu2016}{XS16}
\bibcite{Ying08}{Yin08}
\bibcite{Yu08}{YV08}
\bibcite{Yu2007}{YVCJ07}
\bibcite{Zhang2015}{ZGF{$^{+}$}15}
\bibcite{Zhang2009}{ZJD09}
\bibcite{Zhang2001}{ZK01}
\citation{Shiroishi2009}
